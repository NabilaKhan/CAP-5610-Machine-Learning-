{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing Data and Creating Dataframe\n",
    "train_df = pd.read_csv('input/train.csv')\n",
    "test_df = pd.read_csv('input/test.csv')\n",
    "# train_df.info()\n",
    "# print(train_df.describe())\n",
    "# train_df.head(8)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Checking for columns with null values in Training Data\n",
    "\n",
    "### Checking for null values in features \"Pclass\"\n",
    "# bool_series = pd.isnull(train_df[\"Pclass\"]) \n",
    "# train_df[bool_series]\n",
    "\n",
    "### Checking for null values in features \"Sex\"\n",
    "# bool_series = pd.isnull(train_df[\"Sex\"]) \n",
    "# train_df[bool_series] \n",
    "\n",
    "### Checking for null values in features \"Age\"\n",
    "# bool_series = pd.isnull(train_df[\"Age\"])     #has empty values\n",
    "# train_df[bool_series] \n",
    "\n",
    "### Checking for null values in features \"SibSp\"\n",
    "# bool_series = pd.isnull(train_df[\"SibSp\"]) \n",
    "# train_df[bool_series] \n",
    "\n",
    "### Checking for null values in features \"Parch\"\n",
    "# bool_series = pd.isnull(train_df[\"Parch\"]) \n",
    "# train_df[bool_series] \n",
    "\n",
    "### Checking for null values in features \"Fare\"\n",
    "# bool_series = pd.isnull(train_df[\"Fare\"]) \n",
    "# train_df[bool_series] \n",
    "\n",
    "### Checking for null values in features \"Embarked\"\n",
    "# bool_series = pd.isnull(train_df[\"Embarked\"])     #has empty values\n",
    "# train_df[bool_series]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Checking for columns with null values in Testing Data\n",
    "\n",
    "### Checking for null values in features \"Pclass\"\n",
    "# bool_series = pd.isnull(test_df[\"Pclass\"]) \n",
    "# test_df[bool_series]\n",
    "\n",
    "### Checking for null values in features \"Sex\"\n",
    "# bool_series = pd.isnull(test_df[\"Sex\"]) \n",
    "# test_df[bool_series] \n",
    "\n",
    "### Checking for null values in features \"Age\"\n",
    "# bool_series = pd.isnull(test_df[\"Age\"])     #has empty values\n",
    "# test_df[bool_series] \n",
    "\n",
    "### Checking for null values in features \"SibSp\"\n",
    "# bool_series = pd.isnull(test_df[\"SibSp\"]) \n",
    "# test_df[bool_series] \n",
    "\n",
    "### Checking for null values in features \"Parch\"\n",
    "# bool_series = pd.isnull(test_df[\"Parch\"]) \n",
    "# test_df[bool_series] \n",
    "\n",
    "### Checking for null values in features \"Fare\"\n",
    "# bool_series = pd.isnull(test_df[\"Fare\"])    #has empty values\n",
    "# test_df[bool_series] \n",
    "\n",
    "### Checking for null values in features \"Embarked\"\n",
    "# bool_series = pd.isnull(test_df[\"Embarked\"])    \n",
    "# test_df[bool_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "413    0\n",
      "414    1\n",
      "415    0\n",
      "416    0\n",
      "417    0\n",
      "Name: Sex, Length: 418, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "### Converting Categorial Feature \"Sex\" to Numeric value [male-> 0, female -> 1]\n",
    "gender_map = {'female':1, 'male':0}\n",
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map(gender_map).astype('int32')\n",
    "\n",
    "print(dataset['Sex'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "### Handling Feature \"Age\"\n",
    "\n",
    "### Filling up missing values in \"Age\" using KNN\n",
    "print(train_df['Age'].isnull().sum())\n",
    "print(test_df['Age'].isnull().sum())\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "\n",
    "for dataset in combine:    \n",
    "    Age_val = dataset['Age'].values\n",
    "    Age_val = Age_val.reshape(-1,1)\n",
    "    imputer.fit(Age_val)\n",
    "    Xtrans = imputer.transform(Age_val)\n",
    "    dataset['Age'] = Xtrans\n",
    "    \n",
    "# print(train_df['Age'].isnull().sum())\n",
    "# print(test_df['Age'].isnull().sum())\n",
    "\n",
    "### Converting Continuous Feature \"Age\" to Ordinal Value\n",
    "\n",
    "for dataset in combine:\n",
    "    for index, row in dataset.iterrows():\n",
    "        if(row['Age'] >= 0 and row['Age'] <= 12):\n",
    "            dataset.loc[index, 'Age'] = 0\n",
    "        elif(row['Age'] > 12 and row['Age'] <= 18):\n",
    "            dataset.loc[index, 'Age'] = 1\n",
    "        elif(row['Age'] > 18 and row['Age'] <= 24):\n",
    "            dataset.loc[index, 'Age'] = 2\n",
    "        elif(row['Age'] > 24 and row['Age'] <= 30):\n",
    "            dataset.loc[index, 'Age'] = 3\n",
    "        elif(row['Age'] > 30 and row['Age'] <= 40):\n",
    "            dataset.loc[index, 'Age'] = 4\n",
    "        elif(row['Age'] > 40 and row['Age'] <= 64):\n",
    "            dataset.loc[index, 'Age'] = 5\n",
    "        elif(row['Age'] > 64):\n",
    "            dataset.loc[index, 'Age'] = 6\n",
    "    dataset['Age'] = train_df['Age'].astype(int) \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Handling Feature \"Cabin\"\n",
    "\n",
    "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"X\": 8}\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].fillna(\"X0\")\n",
    "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
    "    dataset['Deck'] = dataset['Deck'].fillna(0)\n",
    "    dataset['Deck'] = dataset['Deck'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Handling feature \"Embarked\"\n",
    "\n",
    "### Filling up missing values in \"Embarked\" using Highest Frquency\n",
    "emb_high_freq_train = train_df.Embarked.dropna().mode()[0]\n",
    "emb_high_freq_train_count = train_df[\"Embarked\"].value_counts().nlargest(n=1).values[0]\n",
    "emb_high_freq_test = test_df.Embarked.dropna().mode()[0]\n",
    "emb_high_freq_test_count = test_df[\"Embarked\"].value_counts().nlargest(n=1).values[0]\n",
    "\n",
    "if emb_high_freq_train_count >= emb_high_freq_test_count:\n",
    "    emb_high_freq = emb_high_freq_train\n",
    "else:\n",
    "    emb_high_freq = emb_high_freq_test\n",
    "    \n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(emb_high_freq)\n",
    "\n",
    "\n",
    "### Converting Categorial Feature \"Embarked\" to Numeric value [S-> 0, C -> 1, Q -> 2] \n",
    "\n",
    "emb_map = {'S': 0, 'C': 1, 'Q': 2}\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map(emb_map).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Handling feature \"Fare\"\n",
    "\n",
    "### Filling up missing values in \"Embarked\" using Highest Frquency\n",
    "fare_med = test_df.Fare.dropna().median()\n",
    "dataset['Fare'] = dataset['Fare'].fillna(fare_med) \n",
    "\n",
    "### Converting Continuous Feature \"Fare\" to Ordinal Value\n",
    "\n",
    "for dataset in combine:\n",
    "    for index, row in dataset.iterrows():\n",
    "        if(row['Fare'] > -0.001 and row['Fare'] <= 7.91):\n",
    "            dataset.loc[index, 'Fare'] = 0\n",
    "        elif(row['Fare'] > 7.91 and row['Fare'] <= 14.454):\n",
    "            dataset.loc[index, 'Fare'] = 1\n",
    "        elif(row['Fare'] > 14.454 and row['Fare'] <= 31):\n",
    "            dataset.loc[index, 'Fare'] = 2\n",
    "        elif(row['Fare'] > 31 and row['Fare'] <= 512.329):\n",
    "            dataset.loc[index, 'Fare'] = 3\n",
    "    \n",
    "train_df['Fare'] = train_df['Fare'].astype(int)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Handling feature \"SibSp\" and \"Parch\"\n",
    "for dataset in combine:\n",
    "    dataset['Family'] = dataset['SibSp'] + dataset['Parch']\n",
    "    dataset.loc[dataset['Family'] > 0, 'Alone'] = 0\n",
    "    dataset.loc[dataset['Family'] == 0, 'Alone'] = 1\n",
    "    dataset['Alone'] = dataset['Alone'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex  Age  Fare  Embarked  Deck  Family  Alone\n",
      "0         0       3    0    2     0         0     8       1      0\n",
      "1         1       1    1    4     3         1     3       1      0\n",
      "2         1       3    1    3     1         0     8       0      1\n",
      "3         1       1    1    4     3         0     3       1      0\n",
      "4         0       3    0    4     1         0     8       0      1\n",
      "   Pclass  Sex  Age  Fare  Embarked  Deck  Family  Alone\n",
      "0       3    0    2   0.0         2     8       0      1\n",
      "1       3    1    4   0.0         0     8       1      0\n",
      "2       2    0    3   1.0         2     8       0      1\n",
      "3       3    0    4   1.0         0     8       0      1\n",
      "4       3    1    4   1.0         0     8       2      0\n"
     ]
    }
   ],
   "source": [
    "### Drop Columns \n",
    "train_df = train_df.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['PassengerId','Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter tuning on decision tree\n",
    "\n",
    "# X_train = train_df.drop(\"Survived\", axis=1)\n",
    "# Y_train = train_df[\"Survived\"]\n",
    "# X_test  = test_df.copy()\n",
    "\n",
    "# decision_tree = DecisionTreeClassifier(criterion='gini')\n",
    "# decision_tree.fit(X_train, Y_train)\n",
    "# Y_pred = decision_tree.predict(X_test)\n",
    "# acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "# print('DT', acc_decision_tree)\n",
    "\n",
    "# print(decision_tree.get_params())\n",
    "\n",
    "# param_dict = {\n",
    "#     \"criterion\":['gini'],\n",
    "#     \"max_depth\":range(1,50),\n",
    "#     \"min_samples_split\":range(1,50),\n",
    "#     \"min_samples_leaf\":range(1,50)\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(decision_tree,\n",
    "#                    param_grid = param_dict,\n",
    "#                    cv=10,\n",
    "#                    verbose=1,\n",
    "#                    n_jobs=-1)\n",
    "\n",
    "# grid.fit(X_train, Y_train)\n",
    "\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_estimator_)\n",
    "# print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 91.36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Decision_tree_plot.png'"
      ]
     },
     "execution_count": 1064,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Decision Tree\n",
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test  = test_df.copy()\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(criterion='gini', max_depth = 15, min_samples_leaf = 1, min_samples_split = 2)\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "print('Decision Tree Accuracy:', acc_decision_tree)\n",
    "\n",
    "# print(decision_tree.get_params())\n",
    "\n",
    "### Drawing Decision Tree\n",
    "feature_names = ['Pclass', 'Sex', 'Age', 'Fare', 'Family', 'Embarked', 'Deck', 'Alone']\n",
    "class_names = ['0', '1']\n",
    "dot_data = tree.export_graphviz(decision_tree, out_file=None,\n",
    "                                feature_names=feature_names,\n",
    "                                class_names=class_names,\n",
    "                                filled=True)\n",
    "graph = graphviz.Source(dot_data, format=\"png\")\n",
    "graph.render(\"Decision_tree_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.79329609 0.7752809  0.83146067 0.80337079 0.84269663]\n",
      "Mean accuracy after 5-fold cross-validation: 80.92210156299039\n",
      "Standard Deviation: 2.471832962810917\n"
     ]
    }
   ],
   "source": [
    "### 5-fold cross-validation on the decision tree\n",
    "scores = cross_val_score(decision_tree, X_train, Y_train, cv=5, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean accuracy after 5-fold cross-validation:\", scores.mean()*100)\n",
    "print(\"Standard Deviation:\", scores.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy 91.36\n"
     ]
    }
   ],
   "source": [
    "### Random forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "Y_prediction = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "print('Random Forest Accuracy', acc_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.79329609 0.79775281 0.85393258 0.78651685 0.86516854]\n",
      "Mean accuracy after 5-fold cross-validation: 81.93333751804657\n",
      "Standard Deviation: 3.322213929706736\n"
     ]
    }
   ],
   "source": [
    "### 5-fold cross-validation on the random forest\n",
    "scores = cross_val_score(random_forest, X_train, Y_train, cv=5, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean accuracy after 5-fold cross-validation:\", scores.mean()*100)\n",
    "print(\"Standard Deviation:\", scores.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
